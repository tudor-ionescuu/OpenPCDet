2025-11-25 18:23:40,836   INFO  Wandb initialized: pointpillar_1x_waymo_full
2025-11-25 18:23:40,837   INFO  Wandb URL: https://wandb.ai/tudor-ionescu-kaust/pointpillars-waymo/runs/5s9rpikn
2025-11-25 18:23:40,837   INFO  Early stopping initialized with patience=7, min_delta=0.001, mode=min
2025-11-25 18:23:40,837   INFO  Early stopping enabled with patience=7
2025-11-25 18:23:40,837   INFO  ----------- Create dataloader & network & optimizer -----------
wandb: 409 encountered ({"errors":[{"message":"project may already be created, please retry","path":["upsertBucket"]}],"data":{"upsertBucket":null}}), retrying request
2025-11-25 18:23:57,722   INFO  Database filter by min points Vehicle: 1194364 => 1019919
2025-11-25 18:23:57,886   INFO  Database filter by min points Pedestrian: 1114091 => 943716
2025-11-25 18:23:57,900   INFO  Database filter by min points Cyclist: 53344 => 47529
2025-11-25 18:23:58,045   INFO  Database filter by difficulty Vehicle: 1019919 => 1019919
2025-11-25 18:23:58,179   INFO  Database filter by difficulty Pedestrian: 943716 => 943716
2025-11-25 18:23:58,186   INFO  Database filter by difficulty Cyclist: 47529 => 47529
2025-11-25 18:23:58,561   INFO  Loading Waymo dataset
2025-11-25 18:24:06,033   INFO  Total skipped info 0
2025-11-25 18:24:06,033   INFO  Total samples for Waymo dataset: 158081
2025-11-25 18:24:06,037   INFO  Total sampled samples for Waymo dataset: 31617
/home/ionesctn/Code/openpcdet_project/openpcdet-env/lib64/python3.9/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2025-11-25 18:24:07,480   INFO  ----------- Model PointPillar created, param count: 4838760 -----------
2025-11-25 18:24:07,480   INFO  PointPillar(
  (vfe): PillarVFE(
    (pfn_layers): ModuleList(
      (0): PFNLayer(
        (linear): Linear(in_features=11, out_features=32, bias=False)
        (norm): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (1): PFNLayer(
        (linear): Linear(in_features=64, out_features=64, bias=False)
        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
  )
  (backbone_3d): None
  (map_to_bev_module): PointPillarScatter()
  (pfe): None
  (backbone_2d): BaseBEVBackbone(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (2): Sequential(
        (0): ZeroPad2d((1, 1, 1, 1))
        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (2): Sequential(
        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)
        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (dense_head): AnchorHeadSingle(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (dir_loss_func): WeightedCrossEntropyLoss()
    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
    (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))
    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  (point_head): None
  (roi_head): None
)
2025-11-25 18:24:07,482   INFO  **********************Start training waymo_models/pointpillar_1x(waymo_full)**********************
epochs:   0%|          | 0/30 [00:00<?, ?it/s]/home/ionesctn/Code/openpcdet_project/OpenPCDet/tools/train_utils/train_utils.py:22: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=use_amp, init_scale=optim_cfg.get('LOSS_SCALE_FP16', 2.0**16))
                                                /home/ionesctn/Code/openpcdet_project/OpenPCDet/tools/train_utils/train_utils.py:56: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
2025-11-25 18:24:14,364   INFO  Train:    1/30 (  3%) [   0/15809 (  0%)]  Loss: 3.385 (3.39)  LR: 3.000e-04  Time cost: 00:02/12:50:47 [00:06/385:23:50]  Acc_iter 1           Data time: 1.33(1.33)  Forward time: 1.59(1.59)  Batch time: 2.93(2.93)
2025-11-25 18:24:21,219   INFO  Train:    1/30 (  3%) [  49/15809 (  0%)]  Loss: 2.426 (2.85)  LR: 3.000e-04  Time cost: 00:09/51:22 [00:13/25:46:03]  Acc_iter 50          Data time: 0.01(0.03)  Forward time: 0.12(0.16)  Batch time: 0.13(0.20)
2025-11-25 18:24:28,104   INFO  Train:    1/30 (  3%) [  99/15809 (  1%)]  Loss: 3.419 (2.80)  LR: 3.000e-04  Time cost: 00:16/43:38 [00:20/21:57:00]  Acc_iter 100         Data time: 0.01(0.02)  Forward time: 0.13(0.15)  Batch time: 0.13(0.17)
2025-11-25 18:24:35,353   INFO  Train:    1/30 (  3%) [ 149/15809 (  1%)]  Loss: 2.260 (2.68)  LR: 3.000e-04  Time cost: 00:23/41:36 [00:27/20:59:47]  Acc_iter 150         Data time: 0.01(0.02)  Forward time: 0.12(0.14)  Batch time: 0.13(0.16)
2025-11-25 18:24:35,670   INFO
2025-11-25 18:24:42,915   INFO  Train:    1/30 (  3%) [ 199/15809 (  1%)]  Loss: 2.251 (2.59)  LR: 3.000e-04  Time cost: 00:31/40:56 [00:35/20:43:29]  Acc_iter 200         Data time: 0.01(0.02)  Forward time: 0.12(0.14)  Batch time: 0.13(0.16)
2025-11-25 18:24:49,960   INFO  Train:    1/30 (  3%) [ 249/15809 (  2%)]  Loss: 2.261 (2.52)  LR: 3.000e-04  Time cost: 00:38/39:57 [00:42/20:17:19]  Acc_iter 250         Data time: 0.00(0.01)  Forward time: 0.13(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:24:57,144   INFO  Train:    1/30 (  3%) [ 299/15809 (  2%)]  Loss: 2.923 (2.45)  LR: 3.000e-04  Time cost: 00:45/39:22 [00:49/20:03:29]  Acc_iter 300         Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.17(0.15)
2025-11-25 18:24:57,456   INFO
2025-11-25 18:25:04,830   INFO  Train:    1/30 (  3%) [ 349/15809 (  2%)]  Loss: 2.359 (2.41)  LR: 3.000e-04  Time cost: 00:53/39:18 [00:57/20:04:54]  Acc_iter 350         Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:25:11,824   INFO  Train:    1/30 (  3%) [ 399/15809 (  3%)]  Loss: 1.634 (2.37)  LR: 3.000e-04  Time cost: 01:00/38:46 [01:04/19:52:16]  Acc_iter 400         Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:25:18,931   INFO  Train:    1/30 (  3%) [ 449/15809 (  3%)]  Loss: 2.152 (2.33)  LR: 3.000e-04  Time cost: 01:07/38:23 [01:11/19:44:25]  Acc_iter 450         Data time: 0.00(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:25:19,261   INFO
2025-11-25 18:25:26,492   INFO  Train:    1/30 (  3%) [ 499/15809 (  3%)]  Loss: 1.698 (2.30)  LR: 3.000e-04  Time cost: 01:15/38:18 [01:19/19:45:15]  Acc_iter 500         Data time: 0.01(0.01)  Forward time: 0.15(0.14)  Batch time: 0.16(0.15)
2025-11-25 18:25:33,711   INFO  Train:    1/30 (  3%) [ 549/15809 (  3%)]  Loss: 2.096 (2.27)  LR: 3.001e-04  Time cost: 01:22/38:02 [01:26/19:41:01]  Acc_iter 550         Data time: 0.00(0.01)  Forward time: 0.15(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:25:40,712   INFO  Train:    1/30 (  3%) [ 599/15809 (  4%)]  Loss: 2.053 (2.23)  LR: 3.001e-04  Time cost: 01:29/37:43 [01:33/19:34:36]  Acc_iter 600         Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.17(0.15)
2025-11-25 18:25:41,034   INFO
2025-11-25 18:25:48,042   INFO  Train:    1/30 (  3%) [ 649/15809 (  4%)]  Loss: 1.771 (2.20)  LR: 3.001e-04  Time cost: 01:36/37:33 [01:40/19:33:09]  Acc_iter 650         Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:25:55,221   INFO  Train:    1/30 (  3%) [ 699/15809 (  4%)]  Loss: 1.794 (2.17)  LR: 3.001e-04  Time cost: 01:43/37:20 [01:47/19:30:11]  Acc_iter 700         Data time: 0.00(0.01)  Forward time: 0.15(0.14)  Batch time: 0.16(0.15)
2025-11-25 18:26:02,258   INFO  Train:    1/30 (  3%) [ 749/15809 (  5%)]  Loss: 2.198 (2.15)  LR: 3.001e-04  Time cost: 01:50/37:05 [01:54/19:26:07]  Acc_iter 750         Data time: 0.01(0.01)  Forward time: 0.12(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:26:02,585   INFO
2025-11-25 18:26:09,850   INFO  Train:    1/30 (  3%) [ 799/15809 (  5%)]  Loss: 2.046 (2.13)  LR: 3.001e-04  Time cost: 01:58/37:01 [02:02/19:28:00]  Acc_iter 800         Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:26:17,071   INFO  Train:    1/30 (  3%) [ 849/15809 (  5%)]  Loss: 1.645 (2.11)  LR: 3.001e-04  Time cost: 02:05/36:51 [02:09/19:26:13]  Acc_iter 850         Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:26:23,946   INFO  Train:    1/30 (  3%) [ 899/15809 (  6%)]  Loss: 1.618 (2.09)  LR: 3.001e-04  Time cost: 02:12/36:35 [02:16/19:21:34]  Acc_iter 900         Data time: 0.01(0.01)  Forward time: 0.12(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:26:24,263   INFO
2025-11-25 18:26:31,379   INFO  Train:    1/30 (  3%) [ 949/15809 (  6%)]  Loss: 1.496 (2.08)  LR: 3.002e-04  Time cost: 02:19/36:28 [02:23/19:22:03]  Acc_iter 950         Data time: 0.00(0.01)  Forward time: 0.12(0.14)  Batch time: 0.12(0.15)
2025-11-25 18:26:38,408   INFO  Train:    1/30 (  3%) [ 999/15809 (  6%)]  Loss: 1.766 (2.06)  LR: 3.002e-04  Time cost: 02:26/36:16 [02:30/19:19:16]  Acc_iter 1000        Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.17(0.15)
2025-11-25 18:26:45,462   INFO  Train:    1/30 (  3%) [1049/15809 (  7%)]  Loss: 1.906 (2.04)  LR: 3.002e-04  Time cost: 02:34/36:05 [02:37/19:16:56]  Acc_iter 1050        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:26:45,788   INFO
2025-11-25 18:26:52,870   INFO  Train:    1/30 (  3%) [1099/15809 (  7%)]  Loss: 1.704 (2.03)  LR: 3.002e-04  Time cost: 02:41/35:58 [02:45/19:17:20]  Acc_iter 1100        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:26:59,803   INFO  Train:    1/30 (  3%) [1149/15809 (  7%)]  Loss: 1.169 (2.02)  LR: 3.002e-04  Time cost: 02:48/35:46 [02:52/19:14:26]  Acc_iter 1150        Data time: 0.00(0.01)  Forward time: 0.13(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:27:07,087   INFO  Train:    1/30 (  3%) [1199/15809 (  8%)]  Loss: 4.098 (2.01)  LR: 3.003e-04  Time cost: 02:55/35:38 [02:59/19:14:05]  Acc_iter 1200        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:27:07,450   INFO
2025-11-25 18:27:14,719   INFO  Train:    1/30 (  3%) [1249/15809 (  8%)]  Loss: 1.200 (1.99)  LR: 3.003e-04  Time cost: 03:03/35:34 [03:07/19:15:56]  Acc_iter 1250        Data time: 0.00(0.01)  Forward time: 0.16(0.14)  Batch time: 0.16(0.15)
2025-11-25 18:27:21,951   INFO  Train:    1/30 (  3%) [1299/15809 (  8%)]  Loss: 2.152 (1.98)  LR: 3.003e-04  Time cost: 03:10/35:26 [03:14/19:15:12]  Acc_iter 1300        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:27:29,289   INFO  Train:    1/30 (  3%) [1349/15809 (  9%)]  Loss: 1.865 (1.97)  LR: 3.003e-04  Time cost: 03:17/35:19 [03:21/19:15:09]  Acc_iter 1350        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:27:29,647   INFO
2025-11-25 18:27:36,946   INFO  Train:    1/30 (  3%) [1399/15809 (  9%)]  Loss: 1.325 (1.95)  LR: 3.004e-04  Time cost: 03:25/35:15 [03:29/19:16:53]  Acc_iter 1400        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:27:44,218   INFO  Train:    1/30 (  3%) [1449/15809 (  9%)]  Loss: 1.465 (1.94)  LR: 3.004e-04  Time cost: 03:32/35:07 [03:36/19:16:23]  Acc_iter 1450        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:27:51,607   INFO  Train:    1/30 (  3%) [1499/15809 (  9%)]  Loss: 1.402 (1.93)  LR: 3.004e-04  Time cost: 03:40/35:00 [03:44/19:16:32]  Acc_iter 1500        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:27:51,959   INFO
2025-11-25 18:27:59,122   INFO  Train:    1/30 (  3%) [1549/15809 ( 10%)]  Loss: 1.334 (1.92)  LR: 3.004e-04  Time cost: 03:47/34:54 [03:51/19:17:18]  Acc_iter 1550        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:28:06,362   INFO  Train:    1/30 (  3%) [1599/15809 ( 10%)]  Loss: 1.396 (1.91)  LR: 3.005e-04  Time cost: 03:54/34:46 [03:58/19:16:40]  Acc_iter 1600        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:28:13,179   INFO  Train:    1/30 (  3%) [1649/15809 ( 10%)]  Loss: 1.502 (1.90)  LR: 3.005e-04  Time cost: 04:01/34:34 [04:05/19:14:03]  Acc_iter 1650        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:28:13,531   INFO
2025-11-25 18:28:20,667   INFO  Train:    1/30 (  3%) [1699/15809 ( 11%)]  Loss: 1.495 (1.89)  LR: 3.005e-04  Time cost: 04:09/34:28 [04:13/19:14:41]  Acc_iter 1700        Data time: 0.01(0.01)  Forward time: 0.11(0.14)  Batch time: 0.12(0.15)
2025-11-25 18:28:27,797   INFO  Train:    1/30 (  3%) [1749/15809 ( 11%)]  Loss: 1.323 (1.89)  LR: 3.006e-04  Time cost: 04:16/34:19 [04:20/19:13:39]  Acc_iter 1750        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:28:34,802   INFO  Train:    1/30 (  3%) [1799/15809 ( 11%)]  Loss: 2.241 (1.88)  LR: 3.006e-04  Time cost: 04:23/34:09 [04:27/19:12:08]  Acc_iter 1800        Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.16(0.15)
2025-11-25 18:28:35,141   INFO
2025-11-25 18:28:42,258   INFO  Train:    1/30 (  3%) [1849/15809 ( 12%)]  Loss: 1.416 (1.87)  LR: 3.006e-04  Time cost: 04:30/34:03 [04:34/19:12:37]  Acc_iter 1850        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:28:49,103   INFO  Train:    1/30 (  3%) [1899/15809 ( 12%)]  Loss: 1.190 (1.86)  LR: 3.007e-04  Time cost: 04:37/33:52 [04:41/19:10:31]  Acc_iter 1900        Data time: 0.01(0.01)  Forward time: 0.12(0.14)  Batch time: 0.12(0.15)
2025-11-25 18:28:56,086   INFO  Train:    1/30 (  3%) [1949/15809 ( 12%)]  Loss: 1.672 (1.85)  LR: 3.007e-04  Time cost: 04:44/33:43 [04:48/19:09:06]  Acc_iter 1950        Data time: 0.00(0.01)  Forward time: 0.15(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:28:56,429   INFO
2025-11-25 18:29:03,339   INFO  Train:    1/30 (  3%) [1999/15809 ( 13%)]  Loss: 1.859 (1.85)  LR: 3.007e-04  Time cost: 04:51/33:35 [04:55/19:08:48]  Acc_iter 2000        Data time: 0.01(0.01)  Forward time: 0.11(0.14)  Batch time: 0.12(0.15)
2025-11-25 18:29:10,432   INFO  Train:    1/30 (  3%) [2049/15809 ( 13%)]  Loss: 1.648 (1.84)  LR: 3.008e-04  Time cost: 04:58/33:26 [05:02/19:07:53]  Acc_iter 2050        Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.17(0.15)
2025-11-25 18:29:12,144   INFO  Save latest model to /home/ionesctn/Code/openpcdet_project/OpenPCDet/output/waymo_models/pointpillar_1x/waymo_full/ckpt/latest_model
2025-11-25 18:29:18,112   INFO  Train:    1/30 (  3%) [2099/15809 ( 13%)]  Loss: 1.444 (1.83)  LR: 3.008e-04  Time cost: 05:06/33:22 [05:10/19:09:13]  Acc_iter 2100        Data time: 0.00(0.01)  Forward time: 0.11(0.14)  Batch time: 0.11(0.15)
2025-11-25 18:29:18,447   INFO
2025-11-25 18:29:25,500   INFO  Train:    1/30 (  3%) [2149/15809 ( 14%)]  Loss: 1.507 (1.82)  LR: 3.009e-04  Time cost: 05:14/33:15 [05:18/19:09:24]  Acc_iter 2150        Data time: 0.01(0.01)  Forward time: 0.12(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:29:32,656   INFO  Train:    1/30 (  3%) [2199/15809 ( 14%)]  Loss: 1.412 (1.82)  LR: 3.009e-04  Time cost: 05:21/33:07 [05:25/19:08:46]  Acc_iter 2200        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:29:39,828   INFO  Train:    1/30 (  3%) [2249/15809 ( 14%)]  Loss: 1.771 (1.81)  LR: 3.009e-04  Time cost: 05:28/32:59 [05:32/19:08:11]  Acc_iter 2250        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:29:40,178   INFO
2025-11-25 18:29:47,400   INFO  Train:    1/30 (  3%) [2299/15809 ( 15%)]  Loss: 1.308 (1.80)  LR: 3.010e-04  Time cost: 05:35/32:53 [05:39/19:09:00]  Acc_iter 2300        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:29:54,437   INFO  Train:    1/30 (  3%) [2349/15809 ( 15%)]  Loss: 1.402 (1.80)  LR: 3.010e-04  Time cost: 05:42/32:44 [05:46/19:08:00]  Acc_iter 2350        Data time: 0.00(0.01)  Forward time: 0.13(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:30:01,609   INFO  Train:    1/30 (  3%) [2399/15809 ( 15%)]  Loss: 1.869 (1.79)  LR: 3.011e-04  Time cost: 05:50/32:36 [05:54/19:07:28]  Acc_iter 2400        Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.17(0.15)
2025-11-25 18:30:01,964   INFO
2025-11-25 18:30:09,467   INFO  Train:    1/30 (  3%) [2449/15809 ( 15%)]  Loss: 1.435 (1.78)  LR: 3.011e-04  Time cost: 05:58/32:32 [06:01/19:09:09]  Acc_iter 2450        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:30:16,515   INFO  Train:    1/30 (  3%) [2499/15809 ( 16%)]  Loss: 1.334 (1.78)  LR: 3.012e-04  Time cost: 06:05/32:23 [06:09/19:08:12]  Acc_iter 2500        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:30:23,589   INFO  Train:    1/30 (  3%) [2549/15809 ( 16%)]  Loss: 1.877 (1.77)  LR: 3.012e-04  Time cost: 06:12/32:15 [06:16/19:07:23]  Acc_iter 2550        Data time: 0.01(0.01)  Forward time: 0.15(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:30:23,949   INFO
2025-11-25 18:30:31,155   INFO  Train:    1/30 (  3%) [2599/15809 ( 16%)]  Loss: 1.422 (1.77)  LR: 3.013e-04  Time cost: 06:19/32:09 [06:23/19:08:05]  Acc_iter 2600        Data time: 0.00(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:30:38,568   INFO  Train:    1/30 (  3%) [2649/15809 ( 17%)]  Loss: 1.678 (1.76)  LR: 3.013e-04  Time cost: 06:27/32:02 [06:31/19:08:17]  Acc_iter 2650        Data time: 0.01(0.01)  Forward time: 0.17(0.14)  Batch time: 0.18(0.15)
2025-11-25 18:30:45,573   INFO  Train:    1/30 (  3%) [2699/15809 ( 17%)]  Loss: 1.451 (1.76)  LR: 3.013e-04  Time cost: 06:34/31:53 [06:38/19:07:17]  Acc_iter 2700        Data time: 0.01(0.01)  Forward time: 0.15(0.14)  Batch time: 0.16(0.15)
2025-11-25 18:30:45,921   INFO
2025-11-25 18:30:52,919   INFO  Train:    1/30 (  3%) [2749/15809 ( 17%)]  Loss: 1.515 (1.75)  LR: 3.014e-04  Time cost: 06:41/31:46 [06:45/19:07:18]  Acc_iter 2750        Data time: 0.01(0.01)  Forward time: 0.12(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:31:00,118   INFO  Train:    1/30 (  3%) [2799/15809 ( 18%)]  Loss: 1.385 (1.75)  LR: 3.014e-04  Time cost: 06:48/31:38 [06:52/19:06:54]  Acc_iter 2800        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:31:07,181   INFO  Train:    1/30 (  3%) [2849/15809 ( 18%)]  Loss: 1.529 (1.74)  LR: 3.015e-04  Time cost: 06:55/31:30 [06:59/19:06:08]  Acc_iter 2850        Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.17(0.15)
2025-11-25 18:31:07,510   INFO
2025-11-25 18:31:14,732   INFO  Train:    1/30 (  3%) [2899/15809 ( 18%)]  Loss: 1.338 (1.73)  LR: 3.016e-04  Time cost: 07:03/31:24 [07:07/19:06:42]  Acc_iter 2900        Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.16(0.15)
2025-11-25 18:31:21,711   INFO  Train:    1/30 (  3%) [2949/15809 ( 19%)]  Loss: 1.704 (1.73)  LR: 3.016e-04  Time cost: 07:10/31:15 [07:14/19:05:44]  Acc_iter 2950        Data time: 0.00(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:31:28,714   INFO  Train:    1/30 (  3%) [2999/15809 ( 19%)]  Loss: 1.800 (1.72)  LR: 3.017e-04  Time cost: 07:17/31:07 [07:21/19:04:51]  Acc_iter 3000        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:31:29,049   INFO
2025-11-25 18:31:36,243   INFO  Train:    1/30 (  3%) [3049/15809 ( 19%)]  Loss: 1.411 (1.72)  LR: 3.017e-04  Time cost: 07:24/31:00 [07:28/19:05:21]  Acc_iter 3050        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:31:43,212   INFO  Train:    1/30 (  3%) [3099/15809 ( 20%)]  Loss: 1.291 (1.72)  LR: 3.018e-04  Time cost: 07:31/30:52 [07:35/19:04:25]  Acc_iter 3100        Data time: 0.00(0.01)  Forward time: 0.12(0.14)  Batch time: 0.12(0.15)
2025-11-25 18:31:50,251   INFO  Train:    1/30 (  3%) [3149/15809 ( 20%)]  Loss: 1.313 (1.71)  LR: 3.018e-04  Time cost: 07:38/30:43 [07:42/19:03:41]  Acc_iter 3150        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:31:50,585   INFO
2025-11-25 18:31:57,775   INFO  Train:    1/30 (  3%) [3199/15809 ( 20%)]  Loss: 1.177 (1.71)  LR: 3.019e-04  Time cost: 07:46/30:37 [07:50/19:04:09]  Acc_iter 3200        Data time: 0.01(0.01)  Forward time: 0.11(0.14)  Batch time: 0.12(0.15)
2025-11-25 18:32:04,815   INFO  Train:    1/30 (  3%) [3249/15809 ( 21%)]  Loss: 1.301 (1.70)  LR: 3.020e-04  Time cost: 07:53/30:29 [07:57/19:03:26]  Acc_iter 3250        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:32:11,704   INFO  Train:    1/30 (  3%) [3299/15809 ( 21%)]  Loss: 1.142 (1.70)  LR: 3.020e-04  Time cost: 08:00/30:20 [08:04/19:02:22]  Acc_iter 3300        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:32:12,074   INFO
2025-11-25 18:32:19,307   INFO  Train:    1/30 (  3%) [3349/15809 ( 21%)]  Loss: 1.648 (1.69)  LR: 3.021e-04  Time cost: 08:07/30:14 [08:11/19:03:01]  Acc_iter 3350        Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.16(0.15)
2025-11-25 18:32:26,368   INFO  Train:    1/30 (  3%) [3399/15809 ( 22%)]  Loss: 1.251 (1.69)  LR: 3.021e-04  Time cost: 08:14/30:06 [08:18/19:02:23]  Acc_iter 3400        Data time: 0.01(0.01)  Forward time: 0.17(0.14)  Batch time: 0.17(0.15)
2025-11-25 18:32:33,501   INFO  Train:    1/30 (  3%) [3449/15809 ( 22%)]  Loss: 1.185 (1.69)  LR: 3.022e-04  Time cost: 08:22/29:58 [08:26/19:01:56]  Acc_iter 3450        Data time: 0.00(0.01)  Forward time: 0.16(0.14)  Batch time: 0.16(0.15)
2025-11-25 18:32:33,850   INFO
2025-11-25 18:32:41,119   INFO  Train:    1/30 (  3%) [3499/15809 ( 22%)]  Loss: 1.049 (1.68)  LR: 3.023e-04  Time cost: 08:29/29:52 [08:33/19:02:35]  Acc_iter 3500        Data time: 0.00(0.01)  Forward time: 0.13(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:32:48,165   INFO  Train:    1/30 (  3%) [3549/15809 ( 22%)]  Loss: 1.470 (1.68)  LR: 3.023e-04  Time cost: 08:36/29:44 [08:40/19:01:56]  Acc_iter 3550        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:32:55,444   INFO  Train:    1/30 (  3%) [3599/15809 ( 23%)]  Loss: 1.278 (1.67)  LR: 3.024e-04  Time cost: 08:44/29:37 [08:47/19:01:49]  Acc_iter 3600        Data time: 0.01(0.01)  Forward time: 0.16(0.14)  Batch time: 0.17(0.15)
2025-11-25 18:32:55,807   INFO
2025-11-25 18:33:02,881   INFO  Train:    1/30 (  3%) [3649/15809 ( 23%)]  Loss: 1.278 (1.67)  LR: 3.025e-04  Time cost: 08:51/29:30 [08:55/19:02:02]  Acc_iter 3650        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:33:09,887   INFO  Train:    1/30 (  3%) [3699/15809 ( 23%)]  Loss: 1.510 (1.66)  LR: 3.025e-04  Time cost: 08:58/29:22 [09:02/19:01:20]  Acc_iter 3700        Data time: 0.00(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:33:17,039   INFO  Train:    1/30 (  3%) [3749/15809 ( 24%)]  Loss: 3.804 (1.66)  LR: 3.026e-04  Time cost: 09:05/29:14 [09:09/19:00:57]  Acc_iter 3750        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:33:17,414   INFO
2025-11-25 18:33:24,464   INFO  Train:    1/30 (  3%) [3799/15809 ( 24%)]  Loss: 1.524 (1.66)  LR: 3.027e-04  Time cost: 09:13/29:07 [09:16/19:01:09]  Acc_iter 3800        Data time: 0.00(0.01)  Forward time: 0.12(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:33:31,651   INFO  Train:    1/30 (  3%) [3849/15809 ( 24%)]  Loss: 1.282 (1.65)  LR: 3.027e-04  Time cost: 09:20/29:00 [09:24/19:00:50]  Acc_iter 3850        Data time: 0.00(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:33:38,812   INFO  Train:    1/30 (  3%) [3899/15809 ( 25%)]  Loss: 1.076 (1.65)  LR: 3.028e-04  Time cost: 09:27/28:52 [09:31/19:00:29]  Acc_iter 3900        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:33:39,135   INFO
2025-11-25 18:33:46,386   INFO  Train:    1/30 (  3%) [3949/15809 ( 25%)]  Loss: 1.015 (1.65)  LR: 3.029e-04  Time cost: 09:34/28:46 [09:38/19:00:58]  Acc_iter 3950        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:33:53,247   INFO  Train:    1/30 (  3%) [3999/15809 ( 25%)]  Loss: 1.473 (1.64)  LR: 3.030e-04  Time cost: 09:41/28:37 [09:45/19:00:01]  Acc_iter 4000        Data time: 0.01(0.01)  Forward time: 0.11(0.14)  Batch time: 0.12(0.15)
2025-11-25 18:34:00,379   INFO  Train:    1/30 (  3%) [4049/15809 ( 26%)]  Loss: 1.169 (1.64)  LR: 3.030e-04  Time cost: 09:48/28:30 [09:52/18:59:38]  Acc_iter 4050        Data time: 0.00(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:34:00,728   INFO
2025-11-25 18:34:07,854   INFO  Train:    1/30 (  3%) [4099/15809 ( 26%)]  Loss: 1.394 (1.64)  LR: 3.031e-04  Time cost: 09:56/28:23 [10:00/18:59:54]  Acc_iter 4100        Data time: 0.01(0.01)  Forward time: 0.12(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:34:12,110   INFO  Save latest model to /home/ionesctn/Code/openpcdet_project/OpenPCDet/output/waymo_models/pointpillar_1x/waymo_full/ckpt/latest_model
2025-11-25 18:34:15,478   INFO  Train:    1/30 (  3%) [4149/15809 ( 26%)]  Loss: 0.9486 (1.63)  LR: 3.032e-04  Time cost: 10:04/28:17 [10:07/19:00:26]  Acc_iter 4150        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:34:22,548   INFO  Train:    1/30 (  3%) [4199/15809 ( 27%)]  Loss: 1.546 (1.63)  LR: 3.033e-04  Time cost: 10:11/28:09 [10:15/18:59:56]  Acc_iter 4200        Data time: 0.00(0.01)  Forward time: 0.18(0.14)  Batch time: 0.18(0.15)
2025-11-25 18:34:22,895   INFO
2025-11-25 18:34:30,294   INFO  Train:    1/30 (  3%) [4249/15809 ( 27%)]  Loss: 0.9403 (1.63)  LR: 3.033e-04  Time cost: 10:18/28:03 [10:22/19:00:41]  Acc_iter 4250        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:34:37,456   INFO  Train:    1/30 (  3%) [4299/15809 ( 27%)]  Loss: 1.111 (1.62)  LR: 3.034e-04  Time cost: 10:26/27:55 [10:29/19:00:20]  Acc_iter 4300        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:34:44,775   INFO  Train:    1/30 (  3%) [4349/15809 ( 28%)]  Loss: 1.225 (1.62)  LR: 3.035e-04  Time cost: 10:33/27:48 [10:37/19:00:17]  Acc_iter 4350        Data time: 0.00(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:34:45,137   INFO
2025-11-25 18:34:52,441   INFO  Train:    1/30 (  3%) [4399/15809 ( 28%)]  Loss: 1.339 (1.62)  LR: 3.036e-04  Time cost: 10:41/27:42 [10:44/19:00:51]  Acc_iter 4400        Data time: 0.00(0.01)  Forward time: 0.13(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:34:59,608   INFO  Train:    1/30 (  3%) [4449/15809 ( 28%)]  Loss: 1.380 (1.62)  LR: 3.037e-04  Time cost: 10:48/27:34 [10:52/19:00:32]  Acc_iter 4450        Data time: 0.00(0.01)  Forward time: 0.14(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:35:06,820   INFO  Train:    1/30 (  3%) [4499/15809 ( 28%)]  Loss: 1.783 (1.61)  LR: 3.037e-04  Time cost: 10:55/27:27 [10:59/19:00:17]  Acc_iter 4500        Data time: 0.01(0.01)  Forward time: 0.15(0.14)  Batch time: 0.16(0.15)
2025-11-25 18:35:07,189   INFO
2025-11-25 18:35:14,722   INFO  Train:    1/30 (  3%) [4549/15809 ( 29%)]  Loss: 1.241 (1.61)  LR: 3.038e-04  Time cost: 11:03/27:21 [11:07/19:01:14]  Acc_iter 4550        Data time: 0.01(0.01)  Forward time: 0.18(0.14)  Batch time: 0.19(0.15)
2025-11-25 18:35:22,090   INFO  Train:    1/30 (  3%) [4599/15809 ( 29%)]  Loss: 2.848 (1.61)  LR: 3.039e-04  Time cost: 11:10/27:14 [11:14/19:01:15]  Acc_iter 4600        Data time: 0.00(0.01)  Forward time: 0.13(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:35:29,443   INFO  Train:    1/30 (  3%) [4649/15809 ( 29%)]  Loss: 1.094 (1.60)  LR: 3.040e-04  Time cost: 11:18/27:07 [11:21/19:01:14]  Acc_iter 4650        Data time: 0.01(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:35:29,772   INFO
2025-11-25 18:35:36,715   INFO  Train:    1/30 (  3%) [4699/15809 ( 30%)]  Loss: 1.216 (1.60)  LR: 3.041e-04  Time cost: 11:25/26:59 [11:29/19:01:05]  Acc_iter 4700        Data time: 0.01(0.01)  Forward time: 0.12(0.14)  Batch time: 0.13(0.15)
2025-11-25 18:35:44,003   INFO  Train:    1/30 (  3%) [4749/15809 ( 30%)]  Loss: 1.352 (1.60)  LR: 3.042e-04  Time cost: 11:32/26:52 [11:36/19:00:57]  Acc_iter 4750        Data time: 0.00(0.01)  Forward time: 0.13(0.14)  Batch time: 0.14(0.15)
2025-11-25 18:35:51,273   INFO  Train:    1/30 (  3%) [4799/15809 ( 30%)]  Loss: 1.358 (1.60)  LR: 3.043e-04  Time cost: 11:39/26:45 [11:43/19:00:48]  Acc_iter 4800        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
2025-11-25 18:35:51,618   INFO
2025-11-25 18:35:58,630   INFO  Train:    1/30 (  3%) [4849/15809 ( 31%)]  Loss: 1.599 (1.59)  LR: 3.044e-04  Time cost: 11:47/26:38 [11:51/19:00:47]  Acc_iter 4850        Data time: 0.01(0.01)  Forward time: 0.14(0.14)  Batch time: 0.15(0.15)
